# ğŸ­ CamEmotions
AplicaciÃ³n web que analiza emociones en tiempo real a travÃ©s de la cÃ¡mara usando **IA con TensorFlow.js** y **Face-API**.  
Detecta expresiones faciales (feliz, triste, enojado, sorprendido, etc.) y las clasifica en un mensaje descriptivo.  
Cada captura se guarda localmente junto con su resultado y se muestra en un historial ordenado de forma anti-cronolÃ³gica.

---

## ğŸ§  CaracterÃ­sticas principales

- ğŸ§â€â™‚ï¸ DetecciÃ³n automÃ¡tica de rostros con **TinyFaceDetector**  
- ğŸ˜Š ClasificaciÃ³n de emociones con **FaceExpressionNet**  
- ğŸ’¾ Guarda cada foto y resultado localmente usando **IndexedDB (localforage)**  
- ğŸ•’ Historial en orden de mÃ¡s reciente a mÃ¡s antiguo  
- ğŸ”’ Todo funciona **localmente**, sin conexiÃ³n ni envÃ­o de datos a la nube  
- ğŸŒ Funciona directamente en el navegador (no requiere instalaciÃ³n especial)

---

## âš™ï¸ Requisitos

- **Node.js** versiÃ³n 18 o superior  
  ğŸ‘‰ [https://nodejs.org/](https://nodejs.org/)  
- **npm** (incluido con Node.js)
- Una cÃ¡mara funcional (integrada o externa)
- Navegador compatible con WebGL (Chrome, Edge, Firefox)

---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

### 1 Clonar el repositorio
Abre una terminal (Git Bash o VS Code) y ejecuta:

```bash
git clone https://github.com/Danny27HA/CamEmotions.git
cd CamEmotions
```
### 2 Instalar dependencias
```bash
npm install
```
Esto instalarÃ¡ todas las librerÃ­as necesarias:
@vladmandic/face-api

@tensorflow/tfjs
@tensorflow/tfjs-backend-webgl
localforage
uuid
react
vite

### 3 Verificar modelos
AsegÃºrate de tener los modelos dentro de:

public/models/  Estos archivos incluyen:

tiny_face_detector_model-weights_manifest.json
face_landmark_68_model-weights_manifest.json
face_expression_model-weights_manifest.json
y sus respectivos .bin.

### 4 Ejecutar en modo desarrollo
```bash
npm run dev
```
La terminal mostrarÃ¡ algo como:

VITE v7.x.x  ready in 800 ms
âœ  Local: http://localhost:5173/


Abre ese enlace en tu navegador y permite el acceso a la cÃ¡mara.
